---
layout: post
title:  "Common Optimization Algorithms"
date:   2023-02-16 22:45:00 +0100
comments: True
share: True
categories: Machine learning
---

## The Learning Process

An important question to ask is what does it mean to learn in Machine Learning/Deep Learning? The answer is simple the goal of a Machine Learning model is to represent the knowledge of most data points with the help of a function which can either be linear or non linear. So how do we decide which function to choose to represent the data points? We use weights and biases to represent the function and randomly assign them a value, then we go on to then iteratively modify the weights with the help of cost function/loss function. When we minimize the cost function we then bring the prediction function closer to the data points. 

How to go about the minimization process? For this we use the optimization algorithms such as gradient descent, Stochastic gradient descent etc

## The Gradient Descent Algorithm


## Stochastic Gradient Descent

### The need for stochasticity

### How it works 

### Momentum in SGD

## ADAM optimization

## Other optimization algorithms 


